{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI Lab 3: Spike Sorting with PCA\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Fall 2015 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Task 1: Two Neuron Spike Sorting](#task1)\n",
    "* [Task 2: Three Neuron Spike Sorting](#task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we saw that if we have the spike timestamps from some neurons and the corresponding joint angle of the subject, we can create a model to predict the joint angle of a subject from some more spike timestamps. These spike timestamps are gathered from electrodes, but the electrodes could be recording more than 1 neuron at the same time. To make predictions based on neuron firing rates, we need to be able to distinguish spikes that come from different neurons. \n",
    "\n",
    "Luckily for us, it is highly unlikely for two neurons next to each other to fire at precisely the same time, so in practice the \"average\" potential waveform looks like a sum of spike waveforms from different neurons. Additionally, each neuron has its own spike \"signature\" unique to that neuron. This is due to the physical characteristics of neurons, such as their shape and structure. It is impossible to know beforehand how many neurons an electrode measures or what each neuron's spike waveform looks like, so we must first separate the spikes from the different neurons near the electrode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "##<span style=\"color:blue\">Task 1: Two Neuron Spike Sorting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spike occurs when the potential passes a certain threshold in a neuron. In the data set we have, each recorded waveform contains `N=32` samples taken at a sampling frequency of 40kHz, which means the time difference between each consecutive sample is 800$\\mu$s. We can represent each vector exactly with any 32-dimensional basis, as long as the vectors making up the basis are linearly independent. However, we want to compute a minimal set of basis that brings out the features of the data using Principal Component Analysis (PCA).\n",
    "\n",
    "For this lab, we will work with data from a single electrode which records up to 3 different neurons. We provide both training and test sets with two and three neurons. The two neuron data set lets us visualize using a 2D scatter plot while the three neuron data set requres a 3D scatter plots. The neurons have also been presorted using a professional software, so we can check our model against presorted data.\n",
    "\n",
    "Import the data sets and see the average waveform for each presorted neuron by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load data\n",
    "presorted = {k: v for k, v in scipy.io.loadmat('spike_waveforms').items() \\\n",
    "             if k in ('sig118a_wf', 'sig118b_wf', 'sig118c_wf')}\n",
    "presorted = [presorted['sig118a_wf'], presorted['sig118b_wf'], presorted['sig118c_wf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_training_set(data):\n",
    "    \"\"\" Separate data set into 2 sets. \n",
    "    1/6 of the dataset is training set and the rest is test set\n",
    "    Parameter:\n",
    "        data: waveform data (width = number of samples per spike)\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    idx_training = np.random.choice(n, n//6, replace=False)\n",
    "    training_set = data[idx_training]\n",
    "    test_set = [data[i] for i in range(n) if n not in idx_training]\n",
    "    return training_set, test_set\n",
    "\n",
    "# Create training and testing dataset\n",
    "two_neurons_training, two_neurons_test = _make_training_set(np.concatenate(presorted[1:]))\n",
    "three_neurons_training, three_neurons_test = _make_training_set(np.concatenate(presorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what the spikes look like. Below, we first plot 100 random spikes. Then, we plot the 3 distinct neuron's shape, taking the average over all of the samples gathered from that neuron based on the presorted data. The goal of this lab is to classify each of the line in the first plot to one of the neurons in the second plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 100 random spikes\n",
    "for waveforms in three_neurons_training[:100]:\n",
    "    plt.plot(waveforms)\n",
    "plt.xlim((0,31))\n",
    "plt.title('100 random spikes')\n",
    "\n",
    "# Plot the 3 spike shapes based on the presorted data\n",
    "plt.figure()\n",
    "for waveforms in presorted:\n",
    "    plt.plot(np.mean(waveforms, axis=0))\n",
    "plt.xlim((0,31))\n",
    "plt.title('Averaged presorted 3 neuron spikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent each spike in a lower dimensional space using PCA. In your implementation of PCA you will decide how to choose these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Using PCA, what will be the principal components if we use data from an electrode that measures 2 neurons?** Describe a special property of the first principal component.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Using PCA, what will be the principal components if we use data from an electrode that measures 3 neurons?** Describe a special property of the first two principal components.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html\">np.linalg.svd</a> in your PCA function. Read the documentation for this function to figure out how to choose the principal components used as the basis for the lower dimensional space.\n",
    "\n",
    "**<font color=\"red\">What does SVD return and how will you use those results?**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the functions below to implement PCA training and classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PCA_train(training_set, n_components):\n",
    "    \"\"\" Use np.linalg.svd to perform PCA\n",
    "    Parameters:\n",
    "        training_set: the data set to perform PCA on (MxN)\n",
    "        n_components: the dimensionality of the basis to return (i.e. number of neurons)\n",
    "    Returns: \n",
    "        The n_components principal components with highest significants and \n",
    "        the mean of each column of the original data\n",
    "    Hint1: Subtract the mean of the data first so the average of each column is 0. The axis \n",
    "        parameter of np.mean is helpful here.\n",
    "    Hint2: Find out a special property of the \"s\" returned by np.linalg.svd either by printing\n",
    "        it out or reading the documentation.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE #\n",
    "    mean = \n",
    "    basis_components = \n",
    "    \n",
    "    return basis_components, mean\n",
    "\n",
    "def PCA_classify(data, new_basis, mean):\n",
    "    \"\"\" Project the data set, adjusted by the mean, into the new basis vectors\n",
    "    Parameters:\n",
    "        data: data to project (MxN)\n",
    "        new_basis: new bases (KxN)\n",
    "        mean: mean of each timestamp from PCA (list of length N)\n",
    "    Returns: \n",
    "        Data projected onto new_basis (MxK)\n",
    "    Hint: Don't forget to adjust the data with the PCA training mean!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First call `PCA_train` on `two_neurons_training` and plot the 2 principal components. Note that since the dataset is randomized, you might get different plots every time you run the second code cell of this notebook (the `_make_training_set` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform PCA and plot the first 2 principal components.\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "two_new_basis, two_mean = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now classify `two_neurons_test` using that model and produce a scatter plot in the new basis. We will also try classifying the presorted data containing 2 neurons so we can see how the model behaves on the 2 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Project the test data two_neurons_test to the basis you found earlier\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "two_classified = \n",
    "\n",
    "plt.scatter(*two_classified.T)\n",
    "plt.title('two_neurons_test')\n",
    "\n",
    "# Project the presorted data and plot it\n",
    "plt.figure()\n",
    "presorted_two_classified = [PCA_classify(spikes, two_new_basis, two_mean) for spikes in presorted[1:]]\n",
    "colors = ['#0000ff', '#00ff00']\n",
    "for dat, color in zip(presorted_two_classified, colors):\n",
    "    plt.scatter(*dat.T, c=color)\n",
    "plt.title('Presorted data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first principal component separates the two neurons in the $x$-axis. Thus, technically we only need 1 principal component to separate the two neurons. This is because the algorithm maximizes the square of the dot product of each signal with the principal component, which results in a large positive dot product with 1 neuron and a large negative dot product with the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "##<span style=\"color:blue\">Task 2: Three Neuron Spike Sorting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `PCA_train` on `three_neurons_training` and plot the 3 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat training with three neuron data, producing 3 principal components\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "three_new_basis, three_mean = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same as the 2 neuron data, but now with the 3 neuron data. We can also see how your model behaves with presorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_3D(data, view_from_top=False):\n",
    "    \"\"\" Takes list of arrays (x, y, z) coordinate triples\n",
    "    One array of triples per color\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors = ['#0000ff', '#00ff00', '#ff0000']\n",
    "    for dat, color in zip(data, colors):\n",
    "        Axes3D.scatter(ax, *dat.T, c=color)\n",
    "    if view_from_top:\n",
    "        ax.view_init(elev=90.,azim=0)                # Move perspective to view from top\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "three_classified = \n",
    "\n",
    "plot_3D([three_classified], False)\n",
    "plt.title('three_neurons_test projected to 3 principal components')\n",
    "\n",
    "presorted_classified = [PCA_classify(spikes, three_new_basis, three_mean) for spikes in presorted]\n",
    "plot_3D(np.array(presorted_classified), False)\n",
    "plt.title('Presorted data projected to 3 principal components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">How many principal components do you actually need to cluster the 3 neurons?** Change the second argument to the `plot_3D` function calls above to True to view the plots \"from the top\" (i.e. looking down the positive z axis).\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
