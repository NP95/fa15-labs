{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI Lab 2: Neuron Firing Rate Predictions\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Fall 2015 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Task 1: Data preparation](#task1)\n",
    "* [Task 2: Predicting joint angle from firing rates](#task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we saw that the energy of brain waves at a certain frequency range allows us to make predictions about whether a subject is moving or not. It turns out that we can make other predictions from the subject's neuron firing rates (i.e. the rate at which the neurons gain enough charge to release a pulse) - in this lab we will see that neuron firing rates are correlated to the angle of the subject's arm.\n",
    "\n",
    "An electrode measures the electric potential at a specific point in the brain. That point might contain one or more neurons, so the electrode is measuring an \"average\" potential. As you have seen in lecture, the recordings might contain a superposition of 2 or 3 neurons. We will explore how to do spike sorting to extract individual neuron's spikes next week. For this week's lab, we get the result of spike sorting - some timestamps of neuron spikes for 153 neurons - and we want to predict a physical property of the subject - the subject's arm angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task1'></a>\n",
    "##<span style=\"color:blue\">Task 1: Data preparation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some spike timestamps of simulated brain waves of a subject whose arm is pointing in certain directions over time. The physical property we are trying to predict is the joint angle $\\theta$. In the diagram below, the subject's arm is pointing towards a point $(x,y)$ in the screen (the ellipse) and $\\theta$ is the angle between the subject's arm and the \"default position\" when the arm extends to $(0,0)$ in the screen. The data we get, however, is in terms of the $(x,y)$ coordinates in the screen so we have to convert those into angles before we can use it to train and predict.\n",
    "\n",
    "<img style=\"width:350px\" src=\"http://inst.eecs.berkeley.edu/~ee16b/fa15/lab_pics/joint-angle.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "spike_times = {k: v[0] for k, v in scipy.io.loadmat('spike_times').items() if k.startswith('sig')}\n",
    "_names = sorted(spike_times.keys())\n",
    "spike_times = [spike_times[_name] for _name in _names]\n",
    "pos = [v for k,v in scipy.io.loadmat('hand_kin').items() if k.startswith('hand_kin')][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our kinematics data (`(x,y)` positions) is sampled at 1kHz (`fs`). To train our model and predict, we want to divide our whole time frame into windows of 100 samples (`window_len`), which corresponds to 0.1 seconds (`window_size`). We will then use 10 (`past_use`) of these 0.1 second windows to predict the angle of the joint at the last window. We need to use some past data because there is some delay between the neuron spikes and the arm movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = 1000\n",
    "window_len = 100\n",
    "window_size = window_len/fs # window size in seconds\n",
    "past_use = 10 # number of past window_len windows of spike data to use to predict the joint angle in the last window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the matrix `pos`, which contains the $(x,y)$ coordinates data of the point in the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(*pos.T)\n",
    "plt.title('Position data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take the average of the position data using non-overlapping windows of `window_len` samples. Since we have to use `past_use` windows to predict the next window, we can only start training at window (`past_use-1`). Also, we need to make sure that we only return valid windows to use for training (i.e. start at window `past_use-1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_positions(pos_data, window_len, past_use):\n",
    "    \"\"\" Calculates the average position in windows of time. Here N is the number of windows\n",
    "    and L is the number of samples per window.\n",
    "    Parameters:\n",
    "        pos_data: Position data (shape: (NL) x 2)\n",
    "        window_len: Length of window in samples (L)\n",
    "        past_use: The number of time windows to use to predict angle in the next time window\n",
    "    Returns:\n",
    "        Average positions within valid time windows for training (shape: (N-past_use+1) x 2) \n",
    "    \"\"\"\n",
    "    avg_pos = np.mean(pos_data.reshape((-1, window_len, 2)), axis=1)[past_use - 1:, :]\n",
    "    return avg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try plotting the average positions\n",
    "\n",
    "avg_pos = average_positions(pos, window_len, past_use)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(*avg_pos.T)\n",
    "plt.title('Average position data in 100ms windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the angles $\\theta$ from the `avg_pos` data <b>assuming the joint is `1` unit away from the screen</b>. The function `np.arctan2` and `np.linalg.norm` might be useful here. When you call `np.linalg.norm`, you can specify the dimension of the matrix to call norm on using the `axis` argument. `np.arctan2` is needed to return an angle in 4 quadrants instead of 2. Consult the angle diagram for a visualizaton. After you find the angles, plot the angles as a histogram to verify your code. The plot should look similar to the one below. The subject spends most of its time in the center of the screen or in one of the edges of the star-shaped trace.\n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"http://inst.eecs.berkeley.edu/~ee16b/fa15/lab_pics/bmi-angles.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the joint angle from avg_pos\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "angles = \n",
    "\n",
    "plt.hist(angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to set up for the model training and prediction is to divide up the spike times into windows of time. Complete the function below to count the number of spikes that happen in each time window of `window_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spike_bins(spike_times, window_size, num_windows):\n",
    "    \"\"\" Divides up the spikes into bins; rounds down timestamps to the nearest bin\n",
    "    Parameters:\n",
    "        spike_times: Array of lists of timestamps (in seconds); each list corresponds to a neuron\n",
    "        window_size: Window size for each bin in seconds\n",
    "        num_windows: Number of time bins to return\n",
    "    Returns:\n",
    "        A num_bins by len(spike_times) matrix of spike counts in each window of time. Each column\n",
    "        corresponds to a neuron and each row corresponds to a time window.\n",
    "    \"\"\"\n",
    "    bins = np.zeros((num_windows, len(spike_times)))\n",
    "    for neuron, neuron_data in enumerate(spike_times):\n",
    "        for timestamp in neuron_data:\n",
    "            # YOUR CODE HERE #\n",
    "            \n",
    "    return bins  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide up spike timestamps to bins\n",
    "\n",
    "spike_data = spike_bins(spike_times, window_size, angles.shape[0] + past_use - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2'></a>\n",
    "##<span style=\"color:blue\">Task 2: Predicting joint angle from firing rates</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up a linear regression to come up with a model for training. Using only 1 neuron at a time and assuming we use `past_use=10` time windows of 100ms (totalling to 1 second) to predict the joint angle at the last time window, we can formulate the equations:\n",
    "$$a_0s_0 + a_1s_1 + a_2s_2 + a_3s_3 + a_4s_4 + ... + a_9s_9 = \\theta_9$$\n",
    "$$a_0s_1 + a_1s_2 + a_2s_3 + a_3s_4 + a_4s_5 + ... + a_9s_{10} = \\theta_{10}$$\n",
    "$$a_0s_2 + a_1s_3 + a_2s_4 + a_3s_5 + a_4s_6 + ... + a_9s_{11} = \\theta_{11}$$\n",
    "etc. where $a_k$ are the regression coeffecients, $s_t$ is the number of spikes this particular neuron has in time window $t$, and $\\theta_t$ is the joint angle at time window $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Reformulate this as a matrix equation and set it up as a least squares problem. Show it to your GSI for checkoff.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to extend this problem setup to multiple neurons later. However, using all 153 neurons might result in overfitting on the training data so the prediction results might not be as good (remember the NASDAQ question in Homework 0?). To stop that from happening, we will only use the top 20 neurons. Try using linear regression on each neuron and find the 20 neurons with the smallest residual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go through all 153 neurons and find the residual vector norm, \n",
    "# then pick the 20 neurons with the smallest residual vector norm\n",
    "# Hint1: the second return value of np.linalg.lstsq is the residual\n",
    "# Hint2: the function np.array.argsort() might be helpful\n",
    "\n",
    "e = []\n",
    "for i in range(0,153):\n",
    "    A = np.zeros((angles.shape[0], past_use))\n",
    "    # YOUR CODE HERE #\n",
    "    \n",
    "    e.append( ... )\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "best = \n",
    "\n",
    "print(\"The best neurons are:\")\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now extend the least square formulation above to use 20 neurons. Our new equations will be\n",
    "$$a_0s_{0,0} + a_1s_{0,1} + ... + a_9s_{0,9} + b_0s_{1,0} + b_1s_{1,1} + ... + b_9s_{1,9} + c_0s_{2,0} + c_1s_{2,1} + ... + c_9s_{2,9} + ... + t_9s_{19,9} = \\theta_9$$\n",
    "$$a_0s_{0,1} + a_1s_{0,2} + ... + a_9s_{0,10} + b_0s_{1,1} + b_1s_{1,2} + ... + b_9s_{1,10} + c_1s_{2,1} + c_2s_{2,2} + ... + c_{10}s_{2,10} + ...  + t_{10}s_{19,10} = \\theta_{10}$$\n",
    "$$a_0s_{0,2} + a_1s_{0,3} + ... + a_9s_{0,11} + b_0s_{1,2} + b_1s_{1,3} + ... + b_9s_{1,11} + c_2s_{2,2} + c_3s_{2,3} + ... + c_{11}s_{2,11} + ...  + t_{10}s_{19,11} = \\theta_{11}$$\n",
    "etc. where $a_k,b_k,...$ are regression coefficients corresponding to components of neuron 0, neuron 1, etc. and $s_{n,t}$ is the number of spikes in neuron $n$ in time window $t$ ($n$ refers to the 20 best spikes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Write down these set of equations in matrix form and set it up as a least squares problem. Show it to your GSI for checkoff.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct the `A` matrix for the problem above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the top 20 neurons to create a model for prediction\n",
    "\n",
    "A = np.zeros((angles.shape[0],past_use*20))\n",
    "\n",
    "# Construct the A matrix\n",
    "# YOUR CODE HERE #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing linear regression on all of the data, we will try creating the model on the first 3/4 of the data and predict the joint angle in the last quarter of the data. Call `np.lstsq` again on `A2`, which contains our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntime = int(np.floor(angles.shape[0]*3/4))\n",
    "print('Train up to sample ' + str(ntime))\n",
    "\n",
    "A2 = A[:ntime,:]         # A matrix containing the traning data\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "x, resid = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot your model versus the actual data. Calculate your model on matrix A2\n",
    "# YOUR CODE HERE #\n",
    "model = \n",
    "\n",
    "timeAxis = np.linspace(0,ntime/10,ntime)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(timeAxis,model)\n",
    "plt.title('Model')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.xlim([0,ntime/10])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(timeAxis,model, color='blue', zorder=0)\n",
    "plt.plot(timeAxis,angles[:ntime], color='green', zorder=5)\n",
    "plt.plot(timeAxis,(angles[:ntime]-model), color='red', zorder=10)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.xlim([0,ntime/10])\n",
    "plt.title('Model vs Data')\n",
    "plt.legend(['Model','Data','Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, the quality of a model is usually measured in something called the \"coeffecient of determination\" or \"R squared value\". Assuming the values of the data are $y_i$ for $i=1,2,...$, the mean of the data is $\\bar{y}$ and the model has values $f_i$ for $i=1,2,...$,\n",
    "$$R^2 = 1 - \\frac{\\sum_i (y_i - f_i)^2}{\\sum_i (y_i - \\bar{y})^2}$$\n",
    "Intuitively the $R^2$ value gives some metric on how much better your model is compared to just modelling with $y=\\bar{y}$. The closer the value to 1 the better. Let's see how our model fares..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_R2(data, model):\n",
    "    \"\"\" Compute R squared, which is a statistical metric on how good your model is.\n",
    "    The closer the R squared to 1, the better.\n",
    "    Parameters:\n",
    "        data: The real data\n",
    "        model: Your prediction/model\n",
    "    Returns:\n",
    "        R squared value\n",
    "    \"\"\"\n",
    "    ss_tot = sum(np.square(data - np.mean(data)))\n",
    "    ss_res = sum(np.square(model - data))\n",
    "    return 1 - ss_res/ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute how good your model is based on R squared\n",
    "\n",
    "Rsquared = compute_R2(angles[:ntime],model)\n",
    "print(\"R^2 of model = \" + str(Rsquared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply your model on the last quarter of the data to predict the joint angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A3 = A[ntime:,:]         # A matrix containing the test data\n",
    "\n",
    "# Compute prediction on matrix A3\n",
    "# YOUR CODE HERE #\n",
    "predicted = \n",
    "\n",
    "timeAxis = np.linspace(ntime/10,(ntime+A3.shape[0])/10,A3.shape[0])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(timeAxis,predicted)\n",
    "plt.title('Model')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.xlim([ntime/10,(ntime+A3.shape[0])/10])\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(timeAxis,predicted, color='blue', zorder=0)\n",
    "plt.plot(timeAxis,angles[ntime:], color='green', zorder=5)\n",
    "plt.plot(timeAxis,(angles[ntime:]-predicted), color='red', zorder=10)\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.xlim([ntime/10,(ntime+A3.shape[0])/10])\n",
    "plt.title('Prediction vs Data')\n",
    "plt.legend(['Prediction','Data','Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rsquared = compute_R2(angles[ntime:],predicted)\n",
    "print(\"R^2 of prediction = \" + str(Rsquared))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
